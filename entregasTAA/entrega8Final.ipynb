{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region.centroid.col</th>\n",
       "      <th>region.centroid.row</th>\n",
       "      <th>region.pixel.count</th>\n",
       "      <th>short.line.density.5</th>\n",
       "      <th>short.line.density.2</th>\n",
       "      <th>vedge.mean</th>\n",
       "      <th>vegde.sd</th>\n",
       "      <th>hedge.mean</th>\n",
       "      <th>hedge.sd</th>\n",
       "      <th>intensity.mean</th>\n",
       "      <th>rawred.mean</th>\n",
       "      <th>rawblue.mean</th>\n",
       "      <th>rawgreen.mean</th>\n",
       "      <th>exred.mean</th>\n",
       "      <th>exblue.mean</th>\n",
       "      <th>exgreen.mean</th>\n",
       "      <th>value.mean</th>\n",
       "      <th>saturation.mean</th>\n",
       "      <th>hue.mean</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>218</td>\n",
       "      <td>178</td>\n",
       "      <td>9</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.547722</td>\n",
       "      <td>1.111110</td>\n",
       "      <td>0.544331</td>\n",
       "      <td>59.629600</td>\n",
       "      <td>52.4444</td>\n",
       "      <td>75.22220</td>\n",
       "      <td>51.222200</td>\n",
       "      <td>-21.55560</td>\n",
       "      <td>46.7778</td>\n",
       "      <td>-25.22220</td>\n",
       "      <td>75.22220</td>\n",
       "      <td>0.318996</td>\n",
       "      <td>-2.04055</td>\n",
       "      <td>path</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113</td>\n",
       "      <td>130</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.250924</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.365148</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.55556</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>-2.66667</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>-2.33333</td>\n",
       "      <td>2.55556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-2.12325</td>\n",
       "      <td>foliage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202</td>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944448</td>\n",
       "      <td>0.772202</td>\n",
       "      <td>1.111110</td>\n",
       "      <td>1.025600</td>\n",
       "      <td>123.037000</td>\n",
       "      <td>111.8890</td>\n",
       "      <td>139.77800</td>\n",
       "      <td>117.444000</td>\n",
       "      <td>-33.44440</td>\n",
       "      <td>50.2222</td>\n",
       "      <td>-16.77780</td>\n",
       "      <td>139.77800</td>\n",
       "      <td>0.199347</td>\n",
       "      <td>-2.29992</td>\n",
       "      <td>sky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>173</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.722220</td>\n",
       "      <td>1.781590</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.749490</td>\n",
       "      <td>43.592600</td>\n",
       "      <td>39.5556</td>\n",
       "      <td>52.88890</td>\n",
       "      <td>38.333300</td>\n",
       "      <td>-12.11110</td>\n",
       "      <td>27.8889</td>\n",
       "      <td>-15.77780</td>\n",
       "      <td>52.88890</td>\n",
       "      <td>0.266914</td>\n",
       "      <td>-1.99886</td>\n",
       "      <td>path</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>197</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.444440</td>\n",
       "      <td>1.515350</td>\n",
       "      <td>2.611110</td>\n",
       "      <td>1.925460</td>\n",
       "      <td>49.592600</td>\n",
       "      <td>44.2222</td>\n",
       "      <td>61.55560</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>-16.11110</td>\n",
       "      <td>35.8889</td>\n",
       "      <td>-19.77780</td>\n",
       "      <td>61.55560</td>\n",
       "      <td>0.302925</td>\n",
       "      <td>-2.02227</td>\n",
       "      <td>path</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   region.centroid.col  region.centroid.row  region.pixel.count   \n",
       "0                  218                  178                   9  \\\n",
       "1                  113                  130                   9   \n",
       "2                  202                   41                   9   \n",
       "3                   32                  173                   9   \n",
       "4                   61                  197                   9   \n",
       "\n",
       "   short.line.density.5  short.line.density.2  vedge.mean  vegde.sd   \n",
       "0              0.111111                   0.0    0.833333  0.547722  \\\n",
       "1              0.000000                   0.0    0.277778  0.250924   \n",
       "2              0.000000                   0.0    0.944448  0.772202   \n",
       "3              0.000000                   0.0    1.722220  1.781590   \n",
       "4              0.000000                   0.0    1.444440  1.515350   \n",
       "\n",
       "   hedge.mean  hedge.sd  intensity.mean  rawred.mean  rawblue.mean   \n",
       "0    1.111110  0.544331       59.629600      52.4444      75.22220  \\\n",
       "1    0.333333  0.365148        0.888889       0.0000       2.55556   \n",
       "2    1.111110  1.025600      123.037000     111.8890     139.77800   \n",
       "3    9.000000  6.749490       43.592600      39.5556      52.88890   \n",
       "4    2.611110  1.925460       49.592600      44.2222      61.55560   \n",
       "\n",
       "   rawgreen.mean  exred.mean  exblue.mean  exgreen.mean  value.mean   \n",
       "0      51.222200   -21.55560      46.7778     -25.22220    75.22220  \\\n",
       "1       0.111111    -2.66667       5.0000      -2.33333     2.55556   \n",
       "2     117.444000   -33.44440      50.2222     -16.77780   139.77800   \n",
       "3      38.333300   -12.11110      27.8889     -15.77780    52.88890   \n",
       "4      43.000000   -16.11110      35.8889     -19.77780    61.55560   \n",
       "\n",
       "   saturation.mean  hue.mean    class  \n",
       "0         0.318996  -2.04055     path  \n",
       "1         1.000000  -2.12325  foliage  \n",
       "2         0.199347  -2.29992      sky  \n",
       "3         0.266914  -1.99886     path  \n",
       "4         0.302925  -2.02227     path  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment = pd.read_csv('convertido.csv')\n",
    "segment.head()#cargo datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#minmaxscaler pone los datos entre 0 y 1\n",
    "#standardscaler pone los datos para que tengan media 0 y desviacion estandar 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = segment['class'].copy()#cogemos la de la clase\n",
    "features = segment.drop(['class'], axis=1)#cogemos predictoras eliminando clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import  LabelBinarizer\n",
    "d = LabelBinarizer().fit(np.unique(target)).transform(target)#label fit unique transform\n",
    "d = d.astype(float)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "st=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=st.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, d_train, d_test = train_test_split(x, d, test_size = 0.33,stratify=target)#separamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=np.ones(d_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recorro columnas de array de test\n",
    "    #regresion lineal con lo que hay en xtrain y los valores de dtrain(1col) y muchas filas para la columna recorrida\n",
    "    #guardo prediccion de las filas en la columna que corresponda sobre las muestras de test\n",
    "#coge el maximo de cada fila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 3 5 3 2 0 0 0 4 2 5 4 6 4 4 5 5 5 4 3 2 6 4 6 0 3 5 5 2 6 5 3 4 4 6 3\n",
      " 1 4 5 4 3 0 3 4 5 6 6 3 3 0 1 2 6 0 2 4 6 2 2 6 4 4 4 1 6 3 6 3 6 5 2 5 0\n",
      " 2 4 4 0 4 5 6 4 0 2 4 6 4 2 2 4 3 4 4 3 3 0 2 6 0 2 2 2 4 5 0 6 1 4 0 3 3\n",
      " 2 0 6 5 3 0 0 2 2 2 2 6 2 5 0 4 0 0 2 2 2 3 0 0 5 4 6 1 1 5 4 5 0 6 3 1 2\n",
      " 4 5 2 2 0 0 2 0 5 3 1 5 2 2 3 3 4 3 2 1 0 4 2 3 6 2 1 6 2 2 2 0 5 0 5 4 6\n",
      " 3 3 5 4 2 6 1 2 5 0 3 6 2 2 3 5 4 0 2 0 4 2 2 6 5 0 3 1 4 6 1 1 4 3 6 3 2\n",
      " 6 4 4 4 4 3 1 1 0 5 3 5 6 6 6 2 3 5 2 6 4 4 0 0 3 3 1 0 3 0 2 5 0 4 2 3 5\n",
      " 3 6 5 3 0 0 1 6 1 5 2 0 3 2 3 5 0 0 5 3 5 2 4 2 0 3 3 5 2 0 3 0 0 0 0 4 4\n",
      " 2 4 2 2 0 5 1 0 0 3 0 4 0 4 0 5 2 3 2 5 3 0 2 2 4 0 0 4 4 0 2 0 4 4 2 4 0\n",
      " 5 5 5 2 6 3 6 0 2 3 2 0 5 5 2 2 6 5 3 1 3 1 3 3 2 4 6 2 3 4 6 0 3 1 1 5 3\n",
      " 2 4 2 0 0 0 4 3 0 5 0 1 6 2 5 2 5 6 1 0 0 2 2 2 1 5 0 4 6 2 2 6 2 6 0 4 0\n",
      " 0 5 0 4 5 1 2 4 2 4 0 5 6 5 4 6 3 4 6 3 2 0 3 4 5 5 3 3 0 3 4 5 6 2 5 0 3\n",
      " 3 4 6 5 2 0 5 1 4 6 3 2 6 4 5 4 3 4 3 3 0 4 5 5 1 5 3 5 3 0 3 6 2 2 5 0 0\n",
      " 2 6 1 0 3 5 2 0 6 0 1 5 4 1 2 0 3 3 2 5 0 0 2 1 5 4 4 3 5 2 5 0 4 4 0 4 5\n",
      " 2 1 0 4 6 6 4 0 2 2 5 4 5 2 4 4 4 5 5 3 3 3 5 0 4 1 2 4 0 6 0 6 0 0 1 6 4\n",
      " 4 2 4 0 6 4 2 6 2 4 5 5 4 3 3 2 2 6 4 4 2 0 3 6 1 3 3 3 0 2 6 6 4 6 1 2 6\n",
      " 4 5 5 6 2 1 5 4 0 2 3 2 3 4 0 5 2 4 5 3 2 3 0 1 5 0 4 4 1 4 2 5 2 5 5 3 5\n",
      " 0 3 2 0 5 2 2 2 2 4 4 4 5 6 0 3 0 3 0 2 0 0 3 0 4 3 0 4 4 4 2 1 6 4 4 5 4\n",
      " 0 0 5 2 3 4 4 4 6 5 4 4 0 2 2 5 3 5 4 0 6 2 5 0 0 0 6 2 2 2 0 2 4 6 6 2 4\n",
      " 5 1 5 2 0 0 5 2 0 2 0 4 3 3 3 6 2 1 3 6 6 5 2 0 4 1 2 3 3 2 4 2 1 6 0 2 5\n",
      " 4 5 6 2 4 4 0 4 3 0 4 0 5 4 3 0 5 4 5 4 2 0 5]\n"
     ]
    }
   ],
   "source": [
    "#FLPA\n",
    "for i in range(d_test.shape[1]):#columnas\n",
    "    regresion = LinearRegression().fit(X_train, d_train[:,i])#entreno en su posicion\n",
    "    y_predict[:,i] = regresion.predict(X_test)#guardo preccion\n",
    "y_predict_test = np.argmax(y_predict, axis=1)#vcojo el maximo\n",
    "\n",
    "#predice cada casilla\n",
    "print(y_predict_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de aciertos = 0.854521625163827\n",
      "\n",
      "Matriz de Confusi贸n:\n",
      " [[107   0   2   0   0   0   0]\n",
      " [ 21  44   2   0  26   4  12]\n",
      " [  1   3  98   0   0   0   7]\n",
      " [  0   0   0 108   1   0   0]\n",
      " [  0   0   0   0 109   0   0]\n",
      " [  0   0   0   0   0 109   0]\n",
      " [  1   1  27   0   3   0  77]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Tasa de aciertos =\", accuracy_score(np.argmax(d_test, axis=1), np.argmax(y_predict, axis=1)))\n",
    "\n",
    "print(\"\\nMatriz de Confusi贸n:\\n\", confusion_matrix(np.argmax(d_test, axis=1), np.argmax(y_predict, axis=1)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Validacion cruzada estratificada</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "K = 10\n",
    "kfold = StratifiedKFold(n_splits=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recorro cada train y test de cada particion\n",
    "# de a 0 a 7\n",
    "    #entreno con los entrenamiento y los de test para la columna seleccionada entre 0 a 7\n",
    "    #guardo en las filas en la columna entre a 0 a 7 marcada la prediccion sobre test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "clase=preprocessing.LabelEncoder()\n",
    "clase.fit(np.unique(target))# guardo las etiqueitas\n",
    "y_auxiliar=clase.transform(target)#transformo\n",
    "target=y_auxiliar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACIERTOS\n",
      "\n",
      "0.8917748917748918\n",
      "0.8225108225108225\n",
      "0.8441558441558441\n",
      "0.8354978354978355\n",
      "0.8701298701298701\n",
      "0.8528138528138528\n",
      "0.8225108225108225\n",
      "0.8354978354978355\n",
      "0.8311688311688312\n",
      "0.8571428571428571\n",
      "\n",
      "\n",
      "Tasa de aciertos = 0.8463203463203464\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#FYFLPA\n",
    "aciertos = np.zeros(K, dtype=float)\n",
    "k = 0\n",
    "print(\"ACIERTOS\\n\")\n",
    "for train_index, test_index in kfold.split(x,y_auxiliar):#recorro los separados: train,test\n",
    "    \n",
    "    y_test = np.zeros((len(test_index), 7), dtype=float)#matrriz con 0\n",
    "    for i in range(7):\n",
    "        regresion = LinearRegression().fit(x[train_index], d[train_index, i])#entreno con los 3. solo la comulna\n",
    "        y_test[:,i] = regresion.predict(x[test_index])#guardo preccion\n",
    "    \n",
    "    aciertos[k] = accuracy_score(target[test_index], np.argmax(y_test, axis=1))# score con el maximo\n",
    "    print(aciertos[k])\n",
    "    k += 1\n",
    "print(\"\\n\\nTasa de aciertos =\", np.mean(aciertos))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "regresion_logistica = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=1000).fit(x, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de aciertos = 0.9410222804718218\n"
     ]
    }
   ],
   "source": [
    "y_test = regresion_logistica.predict(X_test)\n",
    "print(\"Tasa de aciertos =\", accuracy_score(np.argmax(d_test, axis=1), y_test))#maximo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusi贸n:\n",
      " [[108   0   0   0   0   0   1]\n",
      " [  1 103   0   0   1   0   4]\n",
      " [  0   2  92   0   0   0  15]\n",
      " [  0   0   0 109   0   0   0]\n",
      " [  0   0   0   0 109   0   0]\n",
      " [  0   0   0   0   0 109   0]\n",
      " [  0  10  11   0   0   0  88]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Matriz de Confusi贸n:\\n\", confusion_matrix(np.argmax(d_test, axis=1), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACIERTOS\n",
      "\n",
      "0.9567099567099567\n",
      "0.9004329004329005\n",
      "0.9437229437229437\n",
      "0.9437229437229437\n",
      "0.948051948051948\n",
      "0.9393939393939394\n",
      "0.9523809523809523\n",
      "0.9090909090909091\n",
      "0.922077922077922\n",
      "0.9090909090909091\n",
      "\n",
      "\n",
      "Tasa de aciertos = 0.9324675324675324\n"
     ]
    }
   ],
   "source": [
    "#FLPA\n",
    "aciertos = np.zeros(K, dtype=float)#tamano 10\n",
    "k = 0\n",
    "print(\"ACIERTOS\\n\")\n",
    "for train_index, test_index in kfold.split(x, target):\n",
    "    regresion_logistica = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=1000).fit(x[train_index], target[train_index])\n",
    "    y_test = regresion_logistica.predict(x[test_index])#prediccion\n",
    "    aciertos[k] = accuracy_score(target[test_index], y_test)#score\n",
    "    print(aciertos[k])\n",
    "    k += 1\n",
    "print(\"\\n\\nTasa de aciertos =\", np.mean(aciertos))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
